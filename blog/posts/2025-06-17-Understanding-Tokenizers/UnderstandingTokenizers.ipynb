{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2aeeb6e0-d468-4715-a492-750aff24c50a",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Understanding Tokenizers\"\n",
    "author: \"Alonso Silva\"\n",
    "date: \"2025-06-17\"\n",
    "categories: [code, analysis]\n",
    "format:\n",
    "    html:\n",
    "        code-tools: true\n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e15b27-c674-4d6a-bae4-5b548bea8d5e",
   "metadata": {},
   "source": [
    "This post is largely inspired by [Understanding GPT tokenizers](https://simonwillison.net/2023/Jun/8/gpt-tokenizers/) by [Simon Willison](https://simonwillison.net/about/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9e446-81e2-4b87-bba7-1513814ede07",
   "metadata": {},
   "source": [
    "Large Language Models don't work with words, they work with tokens. They take text, convert it into tokens (integers), then predict which tokens should come next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd30e4-994a-4f38-bf5c-b875d763fb0d",
   "metadata": {},
   "source": [
    "To explain this I will use the [`transformers_js_py`](https://github.com/whitphx/transformers.js.py) library which allows us to work with LLMs in the browser through WebAssembly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985a686-99a6-4961-815f-bad7b948bf02",
   "metadata": {},
   "source": [
    "Let's consider a text we want to tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254047c4-a767-4d2d-8d84-63b465be3d47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.014872Z",
     "iopub.status.busy": "2025-06-17T19:10:33.014104Z",
     "iopub.status.idle": "2025-06-17T19:10:33.019743Z",
     "shell.execute_reply": "2025-06-17T19:10:33.018825Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.014824Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "text = \"The dog eats the apples.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff847d39-593d-43cb-b837-9de3e278e6d0",
   "metadata": {},
   "source": [
    "Each LLM has its own tokenizer, so we need to specify which model we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55e75f1-7bdb-4211-9230-1da54899665f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.021392Z",
     "iopub.status.busy": "2025-06-17T19:10:33.020864Z",
     "iopub.status.idle": "2025-06-17T19:10:33.049558Z",
     "shell.execute_reply": "2025-06-17T19:10:33.048613Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.021346Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6872640-b2c2-49f3-b304-7f4a5facbc48",
   "metadata": {},
   "source": [
    "Finally, we can encode it with the model's tokenizer by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e2ec22-973f-4288-8fd6-0a394f6733d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.051197Z",
     "iopub.status.busy": "2025-06-17T19:10:33.050683Z",
     "iopub.status.idle": "2025-06-17T19:10:33.067615Z",
     "shell.execute_reply": "2025-06-17T19:10:33.066715Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.051154Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "code_str = \"\"\"%pip install transformers_js_py\n",
    "\n",
    "from transformers_js_py import import_transformers_js\n",
    "\n",
    "text = \"The dog eats the apples.\"\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "transformers = await import_transformers_js()\n",
    "AutoTokenizer = transformers.AutoTokenizer\n",
    "tokenizer = await AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.encode(text)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edef92e5-1a42-453a-aa65-48757c152ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.069297Z",
     "iopub.status.busy": "2025-06-17T19:10:33.068760Z",
     "iopub.status.idle": "2025-06-17T19:10:33.086237Z",
     "shell.execute_reply": "2025-06-17T19:10:33.085061Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.069236Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import urllib.parse\n",
    "\n",
    "code = urllib.parse.quote(code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2aaaf14-4d4a-4219-9b12-428c42b62040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.088466Z",
     "iopub.status.busy": "2025-06-17T19:10:33.087532Z",
     "iopub.status.idle": "2025-06-17T19:10:33.111850Z",
     "shell.execute_reply": "2025-06-17T19:10:33.111012Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.088417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"https://jupyterlite.github.io/demo/repl/index.html?toolbar=1&kernel=python&promptCellPosition=left&hideCodeInput=0&clearCodeContentOnExecute=1&code=%25pip%20install%20transformers_js_py%0A%0Afrom%20transformers_js_py%20import%20import_transformers_js%0A%0Atext%20%3D%20%22The%20dog%20eats%20the%20apples.%22%0Amodel_id%20%3D%20%22Qwen/Qwen2.5-0.5B-Instruct%22%0A%0Atransformers%20%3D%20await%20import_transformers_js%28%29%0AAutoTokenizer%20%3D%20transformers.AutoTokenizer%0Atokenizer%20%3D%20await%20AutoTokenizer.from_pretrained%28model_id%29%0Atokenizer.encode%28text%29&execute=0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x750f5f51b680>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(f\"https://jupyterlite.github.io/demo/repl/index.html?toolbar=1&kernel=python&promptCellPosition=left&hideCodeInput=0&clearCodeContentOnExecute=1&code={code}&execute=0\", width=900, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd7490-46c7-4386-a5f5-76c06fef3788",
   "metadata": {},
   "source": [
    "\n",
    "You should see as output the following list of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7217201-4c0a-4e7d-91fe-1ec92c626801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.115439Z",
     "iopub.status.busy": "2025-06-17T19:10:33.114969Z",
     "iopub.status.idle": "2025-06-17T19:10:33.128014Z",
     "shell.execute_reply": "2025-06-17T19:10:33.127093Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.115402Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "token_ids = [785, 5562, 49677, 279, 40676, 13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ed7ff-bcd0-484f-8c4a-929112fe2b5d",
   "metadata": {},
   "source": [
    "This list of integers correspond to the token ids. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632072f4-7e93-4b8e-a6c9-181a41e91d54",
   "metadata": {},
   "source": [
    "You can encode other texts by running the following code above:\n",
    "```python\n",
    "tokenizer.encode(\"El perro come las manzanas.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f4344-bd34-4e24-8002-f928b32bf471",
   "metadata": {},
   "source": [
    "You can also modify the `model_id` to see how the tokens change (search for other models in [HuggingFace](https://huggingface.co/models)). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed5bf28-7eed-4084-81bb-b0933b1565a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.129754Z",
     "iopub.status.busy": "2025-06-17T19:10:33.129232Z",
     "iopub.status.idle": "2025-06-17T19:10:33.146512Z",
     "shell.execute_reply": "2025-06-17T19:10:33.145368Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.129712Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "code_str = \"\"\"%pip install transformers_js_py\n",
    "\n",
    "from transformers_js_py import import_transformers_js\n",
    "\n",
    "text = \"The dog eats the apples.\"\n",
    "model_id = \"MaziyarPanahi/Mistral-7B-v0.3\"\n",
    "\n",
    "transformers = await import_transformers_js()\n",
    "AutoTokenizer = transformers.AutoTokenizer\n",
    "tokenizer = await AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.encode(text)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16bfb058-d72b-4d97-b788-28f43637ba12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.148459Z",
     "iopub.status.busy": "2025-06-17T19:10:33.147880Z",
     "iopub.status.idle": "2025-06-17T19:10:33.168599Z",
     "shell.execute_reply": "2025-06-17T19:10:33.167603Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.148404Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import urllib.parse\n",
    "\n",
    "code = urllib.parse.quote(code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "098f6356-0e9d-4ed6-85bf-3cbb148761f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.170316Z",
     "iopub.status.busy": "2025-06-17T19:10:33.169809Z",
     "iopub.status.idle": "2025-06-17T19:10:33.188884Z",
     "shell.execute_reply": "2025-06-17T19:10:33.187811Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.170273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"400\"\n",
       "            src=\"https://jupyterlite.github.io/demo/repl/index.html?toolbar=1&kernel=python&promptCellPosition=left&hideCodeInput=0&clearCodeContentOnExecute=1&code=%25pip%20install%20transformers_js_py%0A%0Afrom%20transformers_js_py%20import%20import_transformers_js%0A%0Atext%20%3D%20%22The%20dog%20eats%20the%20apples.%22%0Amodel_id%20%3D%20%22MaziyarPanahi/Mistral-7B-v0.3%22%0A%0Atransformers%20%3D%20await%20import_transformers_js%28%29%0AAutoTokenizer%20%3D%20transformers.AutoTokenizer%0Atokenizer%20%3D%20await%20AutoTokenizer.from_pretrained%28model_id%29%0Atokenizer.encode%28text%29&execute=0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x750f5f518b90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(f\"https://jupyterlite.github.io/demo/repl/index.html?toolbar=1&kernel=python&promptCellPosition=left&hideCodeInput=0&clearCodeContentOnExecute=1&code={code}&execute=0\", width=900, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79f0ad-1a56-4467-9a8c-16123dbb1988",
   "metadata": {},
   "source": [
    "With this model, you should see as output the following list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d6cb5be-9766-4506-acc3-3293935f3075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.190534Z",
     "iopub.status.busy": "2025-06-17T19:10:33.190026Z",
     "iopub.status.idle": "2025-06-17T19:10:33.205100Z",
     "shell.execute_reply": "2025-06-17T19:10:33.204164Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.190492Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "token_ids_Mistral_7B_v0_3 = [1, 1183, 4682, 1085, 2217, 1040, 1747, 3583, 29491]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007b84b-1c58-45c9-a029-9429c4ea8f63",
   "metadata": {},
   "source": [
    "You can observe that even if the text is the same, these tokens are very different from the previous ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b73ca96-9107-4b5a-ae1d-0c021c9be09f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.206714Z",
     "iopub.status.busy": "2025-06-17T19:10:33.206207Z",
     "iopub.status.idle": "2025-06-17T19:10:33.222834Z",
     "shell.execute_reply": "2025-06-17T19:10:33.221925Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.206672Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "token_ids = [785, 5562, 49677, 279, 40676, 13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ebc9d-0b8d-406e-9885-67892c033bcd",
   "metadata": {},
   "source": [
    "We can do the reverse operation. We take the tokens and convert them to text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32e8092-0073-4e12-8b47-ba5e76e35ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.224502Z",
     "iopub.status.busy": "2025-06-17T19:10:33.223956Z",
     "iopub.status.idle": "2025-06-17T19:10:33.240138Z",
     "shell.execute_reply": "2025-06-17T19:10:33.239232Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.224457Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "code_str = \"\"\"%pip install transformers_js_py\n",
    "\n",
    "from transformers_js_py import import_transformers_js\n",
    "\n",
    "token_ids = [785, 5562, 49677, 279, 40676, 13]\n",
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "transformers = await import_transformers_js()\n",
    "AutoTokenizer = transformers.AutoTokenizer\n",
    "tokenizer = await AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.decode(token_ids)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed66a1c-4164-4ee2-9240-85f3e360a786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.241811Z",
     "iopub.status.busy": "2025-06-17T19:10:33.241300Z",
     "iopub.status.idle": "2025-06-17T19:10:33.258001Z",
     "shell.execute_reply": "2025-06-17T19:10:33.257074Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.241770Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import urllib.parse\n",
    "\n",
    "code = urllib.parse.quote(code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f38f3a9c-aff8-4f36-a883-756ed630dec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T19:10:33.259635Z",
     "iopub.status.busy": "2025-06-17T19:10:33.259111Z",
     "iopub.status.idle": "2025-06-17T19:10:33.278676Z",
     "shell.execute_reply": "2025-06-17T19:10:33.277785Z",
     "shell.execute_reply.started": "2025-06-17T19:10:33.259578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"850\"\n",
       "            height=\"400\"\n",
       "            src=\"https://jupyterlite.github.io/demo/repl/index.html?toolbar=1&kernel=python&promptCellPosition=left&hideCodeInput=0&clearCodeContentOnExecute=1&code=%25pip%20install%20transformers_js_py%0A%0Afrom%20transformers_js_py%20import%20import_transformers_js%0A%0Atoken_ids%20%3D%20%5B785%2C%205562%2C%2049677%2C%20279%2C%2040676%2C%2013%5D%0Amodel_id%20%3D%20%22Qwen/Qwen2.5-0.5B-Instruct%22%0A%0Atransformers%20%3D%20await%20import_transformers_js%28%29%0AAutoTokenizer%20%3D%20transformers.AutoTokenizer%0Atokenizer%20%3D%20await%20AutoTokenizer.from_pretrained%28model_id%29%0Atokenizer.decode%28token_ids%29&execute=0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x750f5f528da0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(f\"https://jupyterlite.github.io/demo/repl/index.html?toolbar=1&kernel=python&promptCellPosition=left&hideCodeInput=0&clearCodeContentOnExecute=1&code={code}&execute=0\", width=850, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb92317-223c-4cf0-9ad5-a4251e52b936",
   "metadata": {},
   "source": [
    "Encoding a text and then decoding it should give the same original text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a28bdf5-f27b-4c6b-bb3f-a1f7d2f4ce1d",
   "metadata": {},
   "source": [
    "**Playing with tokenizers** reveal all sorts of interesting facts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb711cf5-dac0-4581-86cb-d7773d36b6d3",
   "metadata": {},
   "source": [
    "Most common English words are assigned a single token. As demonstrated above:\n",
    "\n",
    "- \"The\": `785`\n",
    "- \" dog\": `5562`\n",
    "- \" eats\": `49677`\n",
    "- \" the\": `279`\n",
    "- \" apples\": `40676`\n",
    "- \".\": `13`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd509bb-0252-4638-aa8b-ef439cb1a0cd",
   "metadata": {},
   "source": [
    "Capitalization is important: \"The\" with a capital T corresponds to token `785`, but \"the\" with lowercase is `1782` and \" the\" with both a leading space and a lowercase t is token `279`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ee94b-cb3d-4e11-b7ec-9d6a3a0f0bd5",
   "metadata": {},
   "source": [
    "Many words also have a token that incorporates a leading space. This makes for much more efficient encoding of full sentences, since they can be encoded without needing to spend a token on each whitespace character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b0a0d-99cb-4e40-927f-ed97b0c0a607",
   "metadata": {},
   "source": [
    "Numbers get their own tokens:\n",
    "\n",
    "- \"0\": `15`\n",
    "- \"1\": `16`\n",
    "- \"2\": `17`\n",
    "- ...\n",
    "- \"9\": `24`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed03d93f-20dc-4aee-9952-5be1781426c4",
   "metadata": {},
   "source": [
    "Languages other than English suffer from less efficient tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2072887c-74c3-4187-92ae-53384c862bc4",
   "metadata": {},
   "source": [
    "\"El perro come las manzanas\" in Spanish is encoded like this:\n",
    "\n",
    "- \"El\": `6582`\n",
    "- \" per\": `817`\n",
    "- \"ro\": `299`\n",
    "- \" come\": `2525`\n",
    "- \" las\": `5141`\n",
    "- \" man\": `883`\n",
    "- \"z\": `89`\n",
    "- \" anas\": `25908`\n",
    "- \".\": `13`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8363a-67fe-41e4-9e3e-1adbfe4429c0",
   "metadata": {},
   "source": [
    "\"Le chien mange les pommes\" in French is encoded like this:\n",
    "\n",
    "- \"Le\": `2304`\n",
    "- \" ch\": `521`\n",
    "- \"ien\": `3591`\n",
    "- \" mange\": `59434`\n",
    "- \" les\": `3541`\n",
    "- \" pom\": `29484`\n",
    "- \" mes\": `8828`\n",
    "- \".\" : `13`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ef66f-6115-4a54-ab1a-a0591cf2b93c",
   "metadata": {},
   "source": [
    "There are all sorts of interesting things like the [glitch tokens](https://simonwillison.net/2023/Jun/8/gpt-tokenizers/#glitch-tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f41c7-1f57-4c06-9469-f3ed71045400",
   "metadata": {},
   "source": [
    "The majority of tokenizers are trained with the [byte-pair encoding algorithm](https://en.wikipedia.org/wiki/Byte-pair_encoding)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f7fbd8-7a4f-41ea-8762-e1845fc18dc8",
   "metadata": {},
   "source": [
    "Many researchers think we should work with bytes and we shouldn't have tokenizers to begin with and they are actively trying to remove them (without much success)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9b9323-8268-4095-9745-bafcb7e5b534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
