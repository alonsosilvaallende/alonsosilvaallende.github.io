{
 "cells": [
  {
   "cell_type": "raw",
   "id": "054ff5a5-f1b9-44d9-96d3-527cc190e300",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Understanding Structured Outputs\"\n",
    "author: \"Alonso Silva\"\n",
    "date: \"2025-07-11\"\n",
    "categories: [code, analysis]\n",
    "image: structured_outputs.jpg\n",
    "filters:\n",
    "  - pyodide\n",
    "format:\n",
    "    html:\n",
    "        code-tools: true\n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f03aac-f54d-4112-bd5c-2064c235fd2f",
   "metadata": {},
   "source": [
    "In my [previous post](https://alonsosilvaallende.github.io/blog/posts/2025-07-05-Understanding-Function-Calling/Understanding_Function_Calling.html), I explained that we can provide a description of a function to the language model and the language model will call that function even if the function itself has not been implemented!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edec204-fb5d-4c32-9ef3-49a54c10756f",
   "metadata": {},
   "source": [
    "This feature has several exciting applications. This is the power behind **structured ouputs** libraries such as [Instructor](https://python.useinstructor.com/) and [Marvin](https://askmarvin.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3216ea-f639-47c6-bcdf-230bd65dd325",
   "metadata": {},
   "source": [
    "In this post, I start by providing a basic example of extracting information with structured outputs, then I give a slightly more complex example by extracting personal information of several people from a text. After that, I give an example of text classification with structured outputs. Finally, I explain how to do structured outputs in WebAssembly (optional but fun if you want to play with structured outputs in the browser in this post itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10dda83-d435-4e24-bfd5-c4a30d5e3f95",
   "metadata": {},
   "source": [
    "The language model has been trained (fine-tuned) to determine (given a prompt and a list of functions descriptions):\n",
    "\n",
    "1. which function to use\n",
    "2. which arguments to use for that function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4772a6-04da-45a0-9607-9b350b0706cc",
   "metadata": {},
   "source": [
    "## Basic Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879a3f3-4baf-48f0-828c-582ef7e64c5a",
   "metadata": {},
   "source": [
    "Let's start with a basic example to see an interesting application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe31a5-661f-4d45-87f7-84445ddaf55c",
   "metadata": {},
   "source": [
    "Let's download a small language model (1.7B parameters) and its tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e865e463-20cd-4ac7-a4c2-01f538f84639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:08.005009Z",
     "iopub.status.busy": "2025-07-16T13:38:08.004286Z",
     "iopub.status.idle": "2025-07-16T13:38:08.010105Z",
     "shell.execute_reply": "2025-07-16T13:38:08.009209Z",
     "shell.execute_reply.started": "2025-07-16T13:38:08.004960Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eceb2ca-1f09-4f3f-bb88-5338d4ae6f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:08.011731Z",
     "iopub.status.busy": "2025-07-16T13:38:08.011216Z",
     "iopub.status.idle": "2025-07-16T13:38:23.079190Z",
     "shell.execute_reply": "2025-07-16T13:38:23.078407Z",
     "shell.execute_reply.started": "2025-07-16T13:38:08.011686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd98c8031a74b078d996869b3b52be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e9d2816a004a1dba56bf16ee98eb27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92bbf1de21d4148ac2f0e4550b26fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132bcc6f2a5145fc9b4586ef9f157cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d47db00f1d4c07827723a8e3de6f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer\n",
    "\n",
    "model_id = \"Qwen/Qwen3-1.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, cache_dir=\"/big_storage/llms/hf_models/\"\n",
    ").to(\"cuda\")\n",
    "streamer = TextIteratorStreamer(tokenizer, skip_prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44441c50-2093-43ac-975c-8e5f1fcb22ed",
   "metadata": {},
   "source": [
    "We can describe a function (which we won't implement) that extracts the city and the country of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1651d559-db8d-4e19-b7cc-e47bfe212726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:23.080205Z",
     "iopub.status.busy": "2025-07-16T13:38:23.079873Z",
     "iopub.status.idle": "2025-07-16T13:38:23.830005Z",
     "shell.execute_reply": "2025-07-16T13:38:23.829283Z",
     "shell.execute_reply.started": "2025-07-16T13:38:23.080187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "        \"name\": \"city_extractor\",\n",
      "        \"strict\": true,\n",
      "        \"parameters\": {\n",
      "            \"description\": \"Extracts the correctly inferred city, state and country name from the text with all the required parameters with correct types.\",\n",
      "            \"properties\": {\n",
      "                \"city\": {\n",
      "                    \"description\": \"city name, e.g. Berkeley\",\n",
      "                    \"title\": \"City\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"state\": {\n",
      "                    \"description\": \"state name, e.g. California\",\n",
      "                    \"title\": \"State\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"country\": {\n",
      "                    \"description\": \"country name, e.g United States\",\n",
      "                    \"title\": \"Country\",\n",
      "                    \"type\": \"string\"\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"city\",\n",
      "                \"state\",\n",
      "                \"country\"\n",
      "            ],\n",
      "            \"title\": \"city_extractor\",\n",
      "            \"type\": \"object\",\n",
      "            \"additionalProperties\": false\n",
      "        },\n",
      "        \"description\": \"Extracts the correctly inferred city, state and country name from the text with all the required parameters with correct types.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "from openai import pydantic_function_tool\n",
    "\n",
    "class city_extractor(BaseModel):\n",
    "    \"\"\"Extracts the correctly inferred city, state and country name from the text with all the required parameters with correct types.\"\"\"\n",
    "\n",
    "    city: str = Field(..., description=\"city name, e.g. Berkeley\")\n",
    "    state: str = Field(..., description=\"state name, e.g. California\")\n",
    "    country: str = Field(..., description=\"country name, e.g United States\")\n",
    "\n",
    "tool = pydantic_function_tool(city_extractor)\n",
    "print(json.dumps(tool, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e679b1e7-5b8c-49ed-b1b5-8ebbc5e1b8e7",
   "metadata": {},
   "source": [
    "We can provide the text `I live in the big apple` and the function description above. We obtain the following response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e2710e2-6e88-4368-bfe9-24da18445589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:23.831311Z",
     "iopub.status.busy": "2025-07-16T13:38:23.831150Z",
     "iopub.status.idle": "2025-07-16T13:38:38.826243Z",
     "shell.execute_reply": "2025-07-16T13:38:38.825507Z",
     "shell.execute_reply.started": "2025-07-16T13:38:23.831297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user says, \"I live in the big apple.\" Let me think about how to handle this. The city_extractor function is supposed to get the city, state, and country from the text. \n",
      "\n",
      "First, the user mentions \"the big apple.\" The Big Apple is a common nickname for New York City. So, the city would be New York. But wait, the function might expect the full name. However, \"New York\" is the correct city name. The state would be New York, but since it's a city, maybe the state is not needed? Wait, the function requires all three: city, state, country. But in this case, the user is referring to a city, not a state. So maybe the state is not applicable here. But the function's parameters require all three. Hmm.\n",
      "\n",
      "Wait, the function's description says it extracts the city, state, and country. But if the user is referring to a city, maybe the state is not present. However, the function might still require the state. But in this case, the user is in New York, which is a state. So the state would be New York, and the country is the United States. \n",
      "\n",
      "But the user's statement is \"I live in the big apple,\" which is a city. So the city is New York, state is New York (since it's a city in the state), and country is United States. But the function might not require the state if it's a city. However, the function's parameters require all three. So maybe the state is still needed. \n",
      "\n",
      "Alternatively, maybe the function is designed to handle cases where the city is the state. But I need to check the function's parameters. The function's properties include state as a string, so even if it's a city, the state is required. But the user is in New York, which is a state. So the state would be New York, and the country is United States. \n",
      "\n",
      "So the city_extractor function would return city: \"New York\", state: \"New York\", country: \"United States\". But I need to make sure that the function can handle that. The function's strict parameter is set to true, so it should correctly infer the parameters. \n",
      "\n",
      "Therefore, the correct call would be to city_extractor with city: \"New York\", state: \"New York\", country: \"United States\".\n",
      "</think>\n",
      "\n",
      "<tool_call>\n",
      "{\"name\": \"city_extractor\", \"arguments\": {\"city\": \"New York\", \"state\": \"New York\", \"country\": \"United States\"}}\n",
      "</tool_call><|im_end|>"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "user_input = \"I live in the big apple\"\n",
    "\n",
    "def generate_response(user_input, tool):\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_input},\n",
    "    ]\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tools=[tool], tokenize=False, add_generation_prompt=True, enable_thinking=True\n",
    "    )\n",
    "    \n",
    "    model_inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    generation_kwargs = dict(\n",
    "        model_inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=4 * 1024,\n",
    "        do_sample=False,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        top_k=50,\n",
    "    )\n",
    "    \n",
    "    from threading import Thread\n",
    "    \n",
    "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "    thread.start()\n",
    "    \n",
    "    assistant_response = \"\"\n",
    "    for chunk in streamer:\n",
    "        assistant_response += chunk\n",
    "        print(chunk, end=\"\")\n",
    "    \n",
    "    thread.join()\n",
    "\n",
    "    return assistant_response\n",
    "\n",
    "assistant_response = generate_response(user_input, tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc5313-5b0c-4a04-ac7a-f31c65bfae15",
   "metadata": {},
   "source": [
    "Inside the `tool_call` xml tags, we get the information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09e95c1-ebb3-46cf-beca-aec4d3bcedef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:38.827059Z",
     "iopub.status.busy": "2025-07-16T13:38:38.826895Z",
     "iopub.status.idle": "2025-07-16T13:38:38.831484Z",
     "shell.execute_reply": "2025-07-16T13:38:38.830846Z",
     "shell.execute_reply.started": "2025-07-16T13:38:38.827045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city: New York\n",
      "state: New York\n",
      "country: United States\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "assistant_response_clean = assistant_response.split(\"<tool_call>\")[-1].split(\"</tool_call>\")[0]\n",
    "assistant_response_json = json.loads(assistant_response_clean)\n",
    "\n",
    "for key in assistant_response_json['arguments']:\n",
    "    print(f\"{key}: {assistant_response_json['arguments'][key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36487ce-f497-4e8f-89ac-81d36d3dcd5c",
   "metadata": {},
   "source": [
    "This is amazing! The language model was able to infer from the text `I live in the big apple` that the city I was referring to was `New York`, the state `New York`  and the country `United States`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba13101-92b9-4028-9ab4-b4600f0eb151",
   "metadata": {},
   "source": [
    "I want to stress again that all I needed was to provide to the language model a description of the function without ever implementing it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd5f31-0803-4482-896b-fbecfbaea1ca",
   "metadata": {},
   "source": [
    "## Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d80cf-7a7d-4499-812f-edb67c4b0af9",
   "metadata": {},
   "source": [
    "A slightly more complicated example but interesting could be to have a personal information extractor. The logic is quite similar to the previous example. We need to describe a function that requires as arguments the information we want to extract (`first_name`, `last_name`, `email`). Here is the description of a function that does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd87bf8-23ec-4fbd-ad31-01be5892feb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:38.832175Z",
     "iopub.status.busy": "2025-07-16T13:38:38.832037Z",
     "iopub.status.idle": "2025-07-16T13:38:38.870475Z",
     "shell.execute_reply": "2025-07-16T13:38:38.869499Z",
     "shell.execute_reply.started": "2025-07-16T13:38:38.832162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "        \"name\": \"PeopleList\",\n",
      "        \"strict\": true,\n",
      "        \"parameters\": {\n",
      "            \"$defs\": {\n",
      "                \"Person\": {\n",
      "                    \"description\": \"It extracts the first name, the last name, and the email address mentioned in the text.\",\n",
      "                    \"properties\": {\n",
      "                        \"first_name\": {\n",
      "                            \"description\": \"the first name\",\n",
      "                            \"title\": \"First Name\",\n",
      "                            \"type\": \"string\"\n",
      "                        },\n",
      "                        \"last_name\": {\n",
      "                            \"description\": \"the last name\",\n",
      "                            \"title\": \"Last Name\",\n",
      "                            \"type\": \"string\"\n",
      "                        },\n",
      "                        \"email\": {\n",
      "                            \"description\": \"the email address\",\n",
      "                            \"title\": \"Email\",\n",
      "                            \"type\": \"string\"\n",
      "                        }\n",
      "                    },\n",
      "                    \"required\": [\n",
      "                        \"first_name\",\n",
      "                        \"last_name\",\n",
      "                        \"email\"\n",
      "                    ],\n",
      "                    \"title\": \"Person\",\n",
      "                    \"type\": \"object\",\n",
      "                    \"additionalProperties\": false\n",
      "                }\n",
      "            },\n",
      "            \"properties\": {\n",
      "                \"people\": {\n",
      "                    \"description\": \"List of people mentioned in the text\",\n",
      "                    \"items\": {\n",
      "                        \"$ref\": \"#/$defs/Person\"\n",
      "                    },\n",
      "                    \"title\": \"People\",\n",
      "                    \"type\": \"array\"\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"people\"\n",
      "            ],\n",
      "            \"title\": \"PeopleList\",\n",
      "            \"type\": \"object\",\n",
      "            \"additionalProperties\": false\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "from typing import List\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"It extracts the first name, the last name, and the email address mentioned in the text.\"\"\"\n",
    "\n",
    "    first_name: str = Field(..., description=\"the first name\")\n",
    "    last_name: str = Field(..., description=\"the last name\")\n",
    "    email: str = Field(..., description=\"the email address\")\n",
    "\n",
    "\n",
    "class PeopleList(BaseModel):\n",
    "    people: List[Person] = Field(\n",
    "        ..., description=\"List of people mentioned in the text\"\n",
    "    )\n",
    "\n",
    "tool = pydantic_function_tool(PeopleList)\n",
    "print(json.dumps(tool, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de64874-32b8-4e70-915b-407cf9795b90",
   "metadata": {},
   "source": [
    "We could have a text that says:\n",
    "\n",
    "> \"My name is John Doe and you can contact me at sales@example.com and she is Jane Doe and can be contacted at support@example.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb82786-4737-48ab-a3f2-d04ea41d0b0c",
   "metadata": {},
   "source": [
    "We can see that this small language model is able to extract the personal information from that text without any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951313dc-37e6-4c24-82fa-b522cb72ea94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:38.872081Z",
     "iopub.status.busy": "2025-07-16T13:38:38.871576Z",
     "iopub.status.idle": "2025-07-16T13:38:48.423671Z",
     "shell.execute_reply": "2025-07-16T13:38:48.422425Z",
     "shell.execute_reply.started": "2025-07-16T13:38:38.872042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let me see. The user provided their name and contact info, and also mentioned someone else, Jane Doe with another email. I need to extract this into a list of people.\n",
      "\n",
      "First, the function PeopleList is available. It requires a list of Person objects, each with first_name, last_name, and email. The user's message has two entries: John Doe and Jane Doe. \n",
      "\n",
      "John Doe has first_name \"John\", last_name \"Doe\", and email \"sales@example.com\". Then Jane Doe has first_name \"Jane\", last_name \"Doe\", and email \"support@example.com\". \n",
      "\n",
      "I need to make sure each person's details are correctly mapped. The function's parameters are strict, so I have to check that all required fields are present. Both entries have first_name, last_name, and email, so that's good. \n",
      "\n",
      "I should structure the people array with each person as an object in the array. The function's example shows the people array as a list of Person objects. So the output should be two Person objects in the people array. \n",
      "\n",
      "No other information is needed here. The user didn't mention any other people, so the list should only include John and Jane. \n",
      "\n",
      "Double-checking the parameters: the function's properties are correct, and the emails are correctly assigned. Alright, that's all.\n",
      "</think>\n",
      "\n",
      "<tool_call>\n",
      "{\"name\": \"PeopleList\", \"arguments\": {\"people\": [{\"first_name\": \"John\", \"last_name\": \"Doe\", \"email\": \"sales@example.com\"}, {\"first_name\": \"Jane\", \"last_name\": \"Doe\", \"email\": \"support@example.com\"}]}}\n",
      "</tool_call><|im_end|>"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "user_input = \"My name is John Doe and you can contact me at sales@example.com and she is Jane Doe and can be contacted at support@example.com\"\n",
    "\n",
    "assistant_response = generate_response(user_input, tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb3fc9f-d764-4dc9-a6d8-642568436a0a",
   "metadata": {},
   "source": [
    "Inside the `tool_call` xml tags, we get the information we wanted to extract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14da5a2e-4fab-45db-9fca-81a51f8cad42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:48.425420Z",
     "iopub.status.busy": "2025-07-16T13:38:48.424888Z",
     "iopub.status.idle": "2025-07-16T13:38:48.432202Z",
     "shell.execute_reply": "2025-07-16T13:38:48.431300Z",
     "shell.execute_reply.started": "2025-07-16T13:38:48.425381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First name: John, Last name: Doe, E-mail: sales@example.com\n",
      "First name: Jane, Last name: Doe, E-mail: support@example.com\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "assistant_response_clean = assistant_response.split(\"<tool_call>\")[-1].split(\"</tool_call>\")[0]\n",
    "assistant_response_json = json.loads(assistant_response_clean)\n",
    "\n",
    "for people in assistant_response_json['arguments']['people']:\n",
    "    print(f\"First name: {people['first_name']}, Last name: {people['last_name']}, E-mail: {people['email']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e227410-4bcf-48ec-9b0a-57334b2d7322",
   "metadata": {},
   "source": [
    "This is great. We can imagine several interesting applications. For example, we could use a small language model to automatically extract from CVs of candidates the information we are interested in and put it into a database instead of asking candidates to put that information themselves. Similarly, we could extract some specific information that we are interested in from websites (as an example, I saw an application that was just taking the required ingredients from a collection of cooking recipes websites)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b858abf-56e5-47fb-8661-b6f323797281",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c22f2-676e-484a-8a78-193fc499dc36",
   "metadata": {},
   "source": [
    "Another example which is quite common for `structured outputs` is classification. Suppose we want to determine if an e-mail we received should be forwarded to the IT department or to the Sales department. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24447be0-26ec-4bee-b86f-701e098f5b36",
   "metadata": {},
   "source": [
    "Before language models, to do this task we would need to create a dataset with different emails and the labels at which they correspond to and then train a model to do the classification. Now, we just need to provide a succint description. That's neat!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139bf0f-b791-406a-a70d-eb46348269d7",
   "metadata": {},
   "source": [
    "We can describe a function that requires as arguments the information we want (`IT department` or `Sales department`). Here is the description of a function that does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32a9fa6-2b1c-487b-8fcb-ef6046551dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:48.434075Z",
     "iopub.status.busy": "2025-07-16T13:38:48.433294Z",
     "iopub.status.idle": "2025-07-16T13:38:48.474538Z",
     "shell.execute_reply": "2025-07-16T13:38:48.473621Z",
     "shell.execute_reply.started": "2025-07-16T13:38:48.434036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "        \"name\": \"Classifier\",\n",
      "        \"strict\": true,\n",
      "        \"parameters\": {\n",
      "            \"description\": \"Correctly inferred `team` the email should be directed to with all the required parameters with correct types.\",\n",
      "            \"properties\": {\n",
      "                \"team\": {\n",
      "                    \"description\": \"Team at which should be the email should be directed to\",\n",
      "                    \"enum\": [\n",
      "                        \"IT department\",\n",
      "                        \"Sales department\"\n",
      "                    ],\n",
      "                    \"title\": \"Team\",\n",
      "                    \"type\": \"string\"\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"team\"\n",
      "            ],\n",
      "            \"title\": \"Classifier\",\n",
      "            \"type\": \"object\",\n",
      "            \"additionalProperties\": false\n",
      "        },\n",
      "        \"description\": \"Correctly inferred `team` the email should be directed to with all the required parameters with correct types.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "from typing import Literal\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Classifier(BaseModel):\n",
    "    \"\"\"Correctly inferred `team` the email should be directed to with all the required parameters with correct types.\"\"\"\n",
    "\n",
    "    team: Literal[\"IT department\", \"Sales department\"] = Field(\n",
    "        ..., description=\"Team at which should be the email should be directed to\"\n",
    "    )\n",
    "tool = pydantic_function_tool(Classifier)\n",
    "print(json.dumps(tool, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b794ebbe-08b9-4ce8-88a8-b17156af94be",
   "metadata": {},
   "source": [
    "We could have an email with the content:\n",
    "\n",
    "> \"I would like to have more information related to the new product.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38054400-faad-472f-9326-48007a83a59a",
   "metadata": {},
   "source": [
    "This small language model is able to classify this text without any problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a8a3609-50aa-412c-a2bb-90c71872f8c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:48.476109Z",
     "iopub.status.busy": "2025-07-16T13:38:48.475622Z",
     "iopub.status.idle": "2025-07-16T13:38:52.952555Z",
     "shell.execute_reply": "2025-07-16T13:38:52.951522Z",
     "shell.execute_reply.started": "2025-07-16T13:38:48.476060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants more information about a new product. Let me see. The available tool is a Classifier that determines the team to send the email to. The team options are IT department or Sales department.\n",
      "\n",
      "Hmm, the user's request is about product information. Typically, Sales departments handle product details and customer inquiries. IT might be involved if there's a technical aspect, but the user didn't mention anything about technical issues. So, the most appropriate team here would be the Sales department. The Classifier function needs to be called with \"Sales department\" as the team parameter. I should make sure the JSON is correctly formatted with the team key and the appropriate value.\n",
      "</think>\n",
      "\n",
      "<tool_call>\n",
      "{\"name\": \"Classifier\", \"arguments\": {\"team\": \"Sales department\"}}\n",
      "</tool_call><|im_end|>"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "user_input = \"I would like to have more information related to the new product.\"\n",
    "\n",
    "assistant_response = generate_response(user_input, tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa70d2c-c9fa-4489-8b7c-cae79acb738b",
   "metadata": {},
   "source": [
    "Inside the `tool_call` xml tags, we get the correct department:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e928f69-c077-4b1f-acac-288b4f8b72a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:52.954141Z",
     "iopub.status.busy": "2025-07-16T13:38:52.953624Z",
     "iopub.status.idle": "2025-07-16T13:38:52.959190Z",
     "shell.execute_reply": "2025-07-16T13:38:52.958512Z",
     "shell.execute_reply.started": "2025-07-16T13:38:52.954102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales department\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "assistant_response_clean = assistant_response.split(\"<tool_call>\")[-1].split(\"</tool_call>\")[0]\n",
    "assistant_response_json = json.loads(assistant_response_clean)\n",
    "\n",
    "print(assistant_response_json['arguments']['team'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52121a82-a7c1-424e-afa3-064f0c0a525c",
   "metadata": {},
   "source": [
    "Let's try another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0cab0be-765a-46c4-a8f3-14acf5dbb894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:38:52.960605Z",
     "iopub.status.busy": "2025-07-16T13:38:52.960094Z",
     "iopub.status.idle": "2025-07-16T13:39:01.067215Z",
     "shell.execute_reply": "2025-07-16T13:39:01.066219Z",
     "shell.execute_reply.started": "2025-07-16T13:38:52.960565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is having trouble exiting Vim. Let me think about how to help them. First, I need to determine which team they're dealing with because the Classifier function is supposed to figure that out. The team options are IT department or Sales department. But how does that relate to exiting Vim?\n",
      "\n",
      "Hmm, maybe the user is using Vim for work, so they might be in the Sales department. But I'm not sure. The Classifier function requires the team to be specified. Since the user is asking about exiting Vim, which is a text editor, perhaps the IT department is more involved with technical support. But the Sales department might be more about business processes. \n",
      "\n",
      "Wait, the function's description says it's for correctly inferred team. The user's query is about a technical issue, so maybe the IT department is the right team. But the user didn't mention anything about IT. This is a bit confusing. The function needs to be called with the team parameter. Since the user is asking about exiting Vim, which is a technical problem, the team might be IT. \n",
      "\n",
      "So, I should call the Classifier function with the team as \"IT department\" to get the appropriate support. Even though the user didn't explicitly mention IT, the context of the problem suggests it. Therefore, the tool call would be to the Classifier function with team: \"IT department\".\n",
      "</think>\n",
      "\n",
      "<tool_call>\n",
      "{\"name\": \"Classifier\", \"arguments\": {\"team\": \"IT department\"}}\n",
      "</tool_call><|im_end|>"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "user_input = \"I cannot exit Vim in my computer. Could you help me with that?\"\n",
    "\n",
    "assistant_response = generate_response(user_input, tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d1a8e-9074-4723-846f-50325afea789",
   "metadata": {},
   "source": [
    "We get again the correct department:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8567fc6c-0d36-4f4c-a3e1-5bce541a2e0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:39:01.071173Z",
     "iopub.status.busy": "2025-07-16T13:39:01.070549Z",
     "iopub.status.idle": "2025-07-16T13:39:01.077292Z",
     "shell.execute_reply": "2025-07-16T13:39:01.076318Z",
     "shell.execute_reply.started": "2025-07-16T13:39:01.071134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT department\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the code\"\n",
    "assistant_response_clean = assistant_response.split(\"<tool_call>\")[-1].split(\"</tool_call>\")[0]\n",
    "assistant_response_json = json.loads(assistant_response_clean)\n",
    "\n",
    "print(assistant_response_json['arguments']['team'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850be37-52eb-418f-9098-5ee1ccc9a9e3",
   "metadata": {},
   "source": [
    "In this example, we have seen only a simple classifier between two classes but the same code can be done with many more classes. Similarly, we can use a whole decision tree structure to classify the text and do different things in the leaf nodes of the decision tree (to minimize delay we could use asynchronous calls to the language model). We could determine to which department should the email be sent and for each department what's the type of question the user is asking (e.g. for sales, to which product is it related to while for IT department, wich program is it related to)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049c23b-232d-4d12-b97b-f0a4613c7a71",
   "metadata": {},
   "source": [
    "## WebAssembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d94b44-c715-400c-9d8f-30986cc9e331",
   "metadata": {},
   "source": [
    "We can do **structured outputs** in the browser thanks to WebAssembly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092aa9d6-3130-4400-b10c-e61ecc11e7d5",
   "metadata": {},
   "source": [
    "We first need to install some packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b5142-e238-400b-971c-b6e28ccbe1da",
   "metadata": {},
   "source": [
    "```{pyodide-python}\n",
    "import micropip\n",
    "\n",
    "await micropip.install(\"transformers_js_py\")\n",
    "await micropip.install(\"openai\") # to use from pydantic to function call\n",
    "print(\"Packages installation completed.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc77d95-830e-4dcb-b4c2-b9982a26cff2",
   "metadata": {},
   "source": [
    "We can download a quantized version of a small language model (0.6B parameters, not everything will work but most of it will). This step should take a few minutes the first time (later it should be stored in the cache):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59eba4b-0fde-4740-b308-74d2486e03ea",
   "metadata": {},
   "source": [
    "```{pyodide-python}\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers_js_py import import_transformers_js\n",
    "from openai import pydantic_function_tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "transformers = await import_transformers_js()\n",
    "\n",
    "model_id = 'onnx-community/Qwen3-0.6B-ONNX'\n",
    "\n",
    "AutoTokenizer = transformers.AutoTokenizer\n",
    "tokenizer = await AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "AutoModelForCausalLM = transformers.AutoModelForCausalLM\n",
    "model = await AutoModelForCausalLM.from_pretrained(model_id)\n",
    "print(\"Model downloaded.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7bcb7f-e539-4141-9a83-cd2230d138fa",
   "metadata": {},
   "source": [
    "We can send a prompt \n",
    "\n",
    "```{pyodide-python}\n",
    "user_input = \"My name is Alonso and I'm 43 years old\"\n",
    "print(\"Prompt received.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422bb69-3a9a-44e9-ac1f-128b636cdb3d",
   "metadata": {},
   "source": [
    "We can define a tool and tokenize the prompt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5654d-896f-4f9b-bdf6-e655076686f8",
   "metadata": {},
   "source": [
    "```{pyodide-python}\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": user_input},\n",
    "]\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"It extracts the name and age.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"the name of the person\")\n",
    "    age: int = Field(..., description=\"the age of the person\")\n",
    "\n",
    "tool = pydantic_function_tool(Person)\n",
    "\n",
    "print(\"Tool definition ready.\")\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, tools=[tool], tokenize=False, add_generation_prompt=True, enable_thinking=True\n",
    ")\n",
    "\n",
    "inputs = tokenizer(prompt)\n",
    "\n",
    "up = np.array(inputs[\"input_ids\"].tolist(), dtype=np.uint32)\n",
    "prompt_length = up.shape[1]\n",
    "print(\"Prompt tokenized.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcfda55-81dd-4791-87b8-b6118bdffa18",
   "metadata": {},
   "source": [
    "This is the generation part and it can take a few minutes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a6cb3-e5fd-4f9c-85e7-08facfbc8cd4",
   "metadata": {},
   "source": [
    "```{pyodide-python}\n",
    "outputs = await model.generate(\n",
    "    **inputs, max_new_tokens=1024, do_sample=False\n",
    ")\n",
    "\n",
    "print(\"outputs ready.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fada3a-5593-4f9a-91c5-f9c36d3b54b6",
   "metadata": {},
   "source": [
    "We decode the assistant response:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59e7532-ffa2-479e-9cd4-da13d883f7fe",
   "metadata": {},
   "source": [
    "```{pyodide-python}\n",
    "ar = np.array(outputs.tolist(), dtype=np.uint32)\n",
    "assistant_response = tokenizer.decode([int(token) for token in ar[0]][prompt_length:], skip_special_tokens=False)\n",
    "print(assistant_response)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9876bd-03a0-4578-816b-e600efb18840",
   "metadata": {},
   "source": [
    "This is the correct extracted information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ddcb00-4e1b-429d-953b-57e5da23917f",
   "metadata": {},
   "source": [
    "```{pyodide-python}\n",
    "assistant_response_clean = assistant_response.split(\"<tool_call>\")[-1].split(\"</tool_call>\")[0]\n",
    "assistant_response_json = json.loads(assistant_response_clean)\n",
    "print(f\"Name: {assistant_response_json['arguments']['name']}\")\n",
    "print(f\"Age: {assistant_response_json['arguments']['age']}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4a1e0-6cf1-4e09-a1d5-88d46525da7e",
   "metadata": {},
   "source": [
    "This tiny language model (quantized 0.6B parameters) was able to extract the information required!\n",
    "\n",
    "Feel free to modify the code and/or prompts and run them in the browser!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
